{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaratrisrinivas/ttt-playground/blob/main/notebooks/05_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TTT Playground - Integration Tests\n",
        "\n",
        "End-to-end tests for the full TTT pipeline:\n",
        "1. **Full Pipeline**: PDF → parse → chunk → learn → clear → Q&A\n",
        "2. **Memory Test**: Process large PDF, monitor VRAM\n",
        "3. **Latency Test**: Measure time per chunk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repo\n",
        "import os\n",
        "if os.path.exists('/content/ttt-playground'):\n",
        "    !cd /content/ttt-playground && git pull\n",
        "    %cd /content/ttt-playground\n",
        "else:\n",
        "    !git clone https://github.com/sivaratrisrinivas/ttt-playground.git\n",
        "    %cd ttt-playground\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, str(Path.cwd()))\n",
        "print(f\"✓ Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q -r requirements.txt\n",
        "print(\"✓ Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    !nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8.2: Full Pipeline Test\n",
        "\n",
        "PDF → parse → chunk → learn → clear context → Q&A comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a test PDF with specific content we can query\n",
        "import fitz\n",
        "\n",
        "def create_content_pdf(filename: str) -> int:\n",
        "    \"\"\"Create PDF with specific facts for testing.\"\"\"\n",
        "    doc = fitz.open()\n",
        "\n",
        "    content = [\n",
        "        \"ACME Corporation Annual Report 2024\",\n",
        "        \"\",\n",
        "        \"Company Overview:\",\n",
        "        \"ACME Corporation was founded in 1985 by John Smith in Silicon Valley.\",\n",
        "        \"The company specializes in manufacturing advanced robotics systems.\",\n",
        "        \"Headquarters is located at 123 Innovation Drive, Palo Alto, CA.\",\n",
        "        \"\",\n",
        "        \"Financial Highlights:\",\n",
        "        \"Revenue for 2024: $4.7 billion\",\n",
        "        \"Net profit margin: 23.5%\",\n",
        "        \"Total employees: 12,500\",\n",
        "        \"\",\n",
        "        \"Key Products:\",\n",
        "        \"1. RoboArm X500 - Industrial robotic arm for manufacturing\",\n",
        "        \"2. AutoNav 3.0 - Autonomous navigation system\",\n",
        "        \"3. SenseAI - Computer vision platform\",\n",
        "        \"\",\n",
        "        \"The CEO is Sarah Johnson, who joined in 2019.\",\n",
        "        \"The CTO is Michael Chen, leading the R&D team of 2,000 engineers.\",\n",
        "    ]\n",
        "\n",
        "    # Repeat content to make document longer for better learning\n",
        "    full_text = \"\\n\".join(content)\n",
        "    for page_num in range(5):  # 5 pages\n",
        "        page = doc.new_page()\n",
        "        page.insert_text((50, 50), f\"Page {page_num + 1}\", fontsize=12)\n",
        "        page.insert_text((50, 80), full_text, fontsize=10)\n",
        "\n",
        "    pages = doc.page_count\n",
        "    doc.save(filename)\n",
        "    doc.close()\n",
        "    print(f\"Created {filename} ({pages} pages)\")\n",
        "    return pages\n",
        "\n",
        "create_content_pdf(\"acme_report.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "from src.models.ttt_model import TTTModel\n",
        "\n",
        "model = TTTModel.from_pretrained(\n",
        "    model_name='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    device='cuda'\n",
        ")\n",
        "print(f\"✓ Model loaded with {len(model.ttt_layers)} TTT layers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse PDF\n",
        "from src.document.pdf_parser import PDFParser\n",
        "\n",
        "parser = PDFParser()\n",
        "with open(\"acme_report.pdf\", \"rb\") as f:\n",
        "    text, page_count = parser.parse(f.read())\n",
        "\n",
        "print(f\"✓ Parsed PDF: {page_count} pages, {len(text)} chars\")\n",
        "print(f\"Preview: {text[:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chunk document\n",
        "from src.document.chunker import DocumentChunker\n",
        "\n",
        "chunker = DocumentChunker(model.tokenizer, chunk_size=512)  # smaller chunks for test\n",
        "chunks = chunker.chunk(text)\n",
        "\n",
        "print(f\"✓ Chunked into {len(chunks)} chunks\")\n",
        "for i, chunk in enumerate(chunks):\n",
        "    print(f\"  Chunk {i}: {chunk.token_count} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Document and train\n",
        "from src.config import Document, DocumentStatus, LearningConfig\n",
        "from src.learning.trainer import TTTTrainer\n",
        "\n",
        "doc = Document(\n",
        "    id=\"acme_test\",\n",
        "    filename=\"acme_report.pdf\",\n",
        "    page_count=page_count,\n",
        "    total_tokens=sum(c.token_count for c in chunks),\n",
        "    chunks=chunks,\n",
        "    status=DocumentStatus.READY\n",
        ")\n",
        "\n",
        "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
        "\n",
        "def progress(idx, total, loss):\n",
        "    print(f\"  Chunk {idx+1}/{total}: loss={loss:.4f}\")\n",
        "\n",
        "metrics = trainer.train_on_document(doc, progress_callback=progress)\n",
        "print(f\"\\n✓ Learning complete:\")\n",
        "print(f\"  Initial loss: {metrics.initial_loss:.4f}\")\n",
        "print(f\"  Final loss: {metrics.final_loss:.4f}\")\n",
        "print(f\"  Time: {metrics.learning_time_seconds:.2f}s\")\n",
        "print(f\"  Weight delta: {metrics.weight_delta_norm:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear context and compare answers\n",
        "from src.inference.generator import Generator\n",
        "\n",
        "model.clear_context()\n",
        "gen = Generator(model=model, tokenizer=model.tokenizer)\n",
        "\n",
        "questions = [\n",
        "    \"Who is the CEO of ACME Corporation?\",\n",
        "    \"What is ACME's revenue?\",\n",
        "    \"Where is ACME headquarters located?\",\n",
        "]\n",
        "\n",
        "print(\"Q&A Comparison (TTT learned vs Base model):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for q in questions:\n",
        "    ttt_ans, base_ans = gen.compare(q, max_tokens=50, temperature=0.0)\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(f\"TTT:  {ttt_ans.text[:100]}\")\n",
        "    print(f\"Base: {base_ans.text[:100]}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ Step 8.2: Full Pipeline Test PASSED\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8.3: Memory Test\n",
        "\n",
        "Process larger PDF, monitor VRAM usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_gpu_memory():\n",
        "    \"\"\"Get current GPU memory usage in GB.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.memory_allocated() / 1024**3\n",
        "    return 0\n",
        "\n",
        "def get_gpu_memory_peak():\n",
        "    \"\"\"Get peak GPU memory usage in GB.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.max_memory_allocated() / 1024**3\n",
        "    return 0\n",
        "\n",
        "# Reset peak memory counter\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "print(f\"Current GPU memory: {get_gpu_memory():.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create larger test PDF (20 pages)\n",
        "def create_large_pdf(filename: str, num_pages: int = 20):\n",
        "    doc = fitz.open()\n",
        "    content = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. \" * 50\n",
        "    for i in range(num_pages):\n",
        "        page = doc.new_page()\n",
        "        page.insert_text((50, 50), f\"Page {i+1}\", fontsize=12)\n",
        "        page.insert_text((50, 80), content, fontsize=10)\n",
        "    doc.save(filename)\n",
        "    doc.close()\n",
        "    print(f\"Created {filename} ({num_pages} pages)\")\n",
        "\n",
        "create_large_pdf(\"large_test.pdf\", num_pages=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse and chunk\n",
        "with open(\"large_test.pdf\", \"rb\") as f:\n",
        "    text, page_count = parser.parse(f.read())\n",
        "\n",
        "chunker = DocumentChunker(model.tokenizer, chunk_size=2048)\n",
        "chunks = chunker.chunk(text)\n",
        "\n",
        "doc = Document(\n",
        "    id=\"large_test\",\n",
        "    filename=\"large_test.pdf\",\n",
        "    page_count=page_count,\n",
        "    total_tokens=sum(c.token_count for c in chunks),\n",
        "    chunks=chunks,\n",
        "    status=DocumentStatus.READY\n",
        ")\n",
        "\n",
        "print(f\"✓ Large doc: {page_count} pages, {len(chunks)} chunks, {doc.total_tokens} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and monitor memory\n",
        "model.reset_learning()\n",
        "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
        "\n",
        "memory_samples = []\n",
        "def memory_callback(idx, total, loss):\n",
        "    mem = get_gpu_memory()\n",
        "    memory_samples.append(mem)\n",
        "    print(f\"  Chunk {idx+1}/{total}: loss={loss:.4f}, VRAM={mem:.2f}GB\")\n",
        "\n",
        "metrics = trainer.train_on_document(doc, progress_callback=memory_callback)\n",
        "\n",
        "peak_mem = get_gpu_memory_peak()\n",
        "print(f\"\\n✓ Memory test results:\")\n",
        "print(f\"  Peak VRAM: {peak_mem:.2f} GB\")\n",
        "print(f\"  Max VRAM during learning: {max(memory_samples):.2f} GB\")\n",
        "\n",
        "# T4 has 16GB, we want to stay under 14GB\n",
        "assert peak_mem < 14.0, f\"Peak VRAM {peak_mem:.2f}GB exceeds 14GB limit!\"\n",
        "print(\"  ✓ VRAM usage within T4 limits (<14GB)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ Step 8.3: Memory Test PASSED\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Step 8.4: Latency Test\n",
        "\n",
        "Measure time per chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from time import perf_counter\n",
        "\n",
        "# Reset and time each chunk\n",
        "model.reset_learning()\n",
        "trainer = TTTTrainer(model=model, config=LearningConfig())\n",
        "\n",
        "chunk_times = []\n",
        "last_time = perf_counter()\n",
        "\n",
        "def timing_callback(idx, total, loss):\n",
        "    global last_time\n",
        "    now = perf_counter()\n",
        "    elapsed = now - last_time\n",
        "    chunk_times.append(elapsed)\n",
        "    last_time = now\n",
        "    print(f\"  Chunk {idx+1}/{total}: {elapsed:.2f}s\")\n",
        "\n",
        "last_time = perf_counter()\n",
        "metrics = trainer.train_on_document(doc, progress_callback=timing_callback)\n",
        "\n",
        "avg_time = sum(chunk_times) / len(chunk_times)\n",
        "print(f\"\\n✓ Latency test results:\")\n",
        "print(f\"  Average time per chunk: {avg_time:.2f}s\")\n",
        "print(f\"  Total learning time: {metrics.learning_time_seconds:.2f}s\")\n",
        "\n",
        "# Target: <3s per 2048-token chunk on T4\n",
        "assert avg_time < 3.0, f\"Average {avg_time:.2f}s exceeds 3s target!\"\n",
        "print(\"  ✓ Latency within target (<3s per chunk)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ Step 8.4: Latency Test PASSED\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ ALL PHASE 8 INTEGRATION TESTS PASSED!\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
